% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

\documentclass[prodmode,acmtecs]{acmsmall} % Aptara syntax

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subfig}
\usepackage{tabulary}
\usepackage{lineno}

\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}

\usepackage{listings}
\lstset{language=C, breaklines=true}

\usepackage[cmex10]{amsmath}
\usepackage{url}

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Metadata Information
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}

% Document starts
\begin{document}

% Page heads
\markboth{F. Luporini et al.}{Optimizing Finite Element Integration through Automated Expression Re-writing and Code Specialization}

% Title portion
\title{Optimizing Finite Element Integration through Automated Expression Re-writing and Code Specialization}
\author{Fabio Luporini
\affil{Imperial College London}
David A. Ham
\affil{Imperial College London}
Paul H.J. Kelly
\affil{Imperial College London}}
% NOTE! Affiliations placed here should be for the institution where the
%       BULK of the research was done. If the author has gone to a new
%       institution, before publication, the (above) affiliation should NOT be changed.
%       The authors 'current' address may be given in the "Author's addresses:" block (below).
%       So for example, Mr. Abdelzaher, the bulk of the research was done at UIUC, and he is
%       currently affiliated with NASA.

\begin{abstract}
Abstract goes here
%
%The code is generated from a high level language for PDEs. An
%invocation of the kernel typically does tensor-like calculators over
%relatively small matrices; e.g., triply nested loops operating on
%about a dozen iterations. Because of the DSL context, COFFEE has a lot
%of flexibility on how it organizes/orders the calculations to tailor
%execution to a target architecture.
%
\end{abstract}

\category{G.1.8}{Numerical Analysis}{Partial Differential Equations -
  Finite element methods}

\category{G.4}{Mathematical Software}{Parallel and vector
  implementations}

\terms{Design, Performance}

\keywords{Finite element integration, local assembly, compilers,
  optimizations, SIMD vectorization}

\acmformat{Fabio Luporini, David A. Ham, and Paul   H. J. Kelly, 2014. 
  Optimizing Finite Element Integration through Automated Expression Re-writing and Code Specialization.}

% At a minimum you need to supply the author names, year and a title.
% IMPORTANT: Full first names whenever they are known, surname last,
% followed by a period.  In the case of two authors, 'and' is placed
% between them.  In the case of three or more authors, the serial
% comma is used, that is, all author names except the last one but
% including the penultimate author's name are followed by a comma, and
% then 'and' is placed before the final author's name.  If only first
% and middle initials are known, then each initial is followed by a
% period and they are separated by a space.  The remaining information
% (journal title, volume, article number, date, etc.) is
% 'auto-generated'.

\begin{bottomstuff}

This research is partly funded by the MAPDES project, by the
Department of Computing at Imperial College London, by EPSRC through
grants EP/I00677X/1, EP/I006761/1, and EP/L000407/1, by NERC grants
NE/K008951/1 and NE/K006789/1, by the U.S.  National Science
Foundation through grants 0811457 and 0926687, by the U.S. Army
through contract W911NF-10-1-000, and by a HiPEAC collaboration
grant. The authors would like to thank Dr. Carlo Bertolli,
Dr. Lawrence Mitchell, and Dr. Francis Russell for their invaluable
suggestions and their contribution to the Firedrake project.

Author's addresses: Fabio Luporini $\&$ Paul H. J. Kelly, Department of Computing,
Imperial College London; David A. Ham, Department of Computing and
Department of Mathematics, Imperial College London; 
\end{bottomstuff}

\maketitle

%Computational cost is a critical limitation in scientific computing,
%especially for finite element simulations. To provide one particular
%example we are particularly concerned about, it has been well
%established that mesh resolution Consequently, our aggressive
%optimization of local assembly, which may even take up to 60% of the
%overall FEM's execution time, directly impacts the performance of
%large-scale scientific simulations running on supercomputers.

\section{Introduction}

%This paper can be thought of as a continuation of the work presented in~\cite{Luporini}: in particular, we answer the remaining open questions, generalize and formalize an approach to minimize redundant computation using a similar philosophy, we show ~\cite{quadrature1}. 


\section{Preliminaries}
\label{sec:background}

\subsection{Quadrature for Finite Element Local Assembly}
%Here we discuss about the computational characteristics of
%computational science kernels. Briefly cite op2 kernels. Emphasis on
%Finite Element Assembly. Generalization and formalization of a Finite
%Element Assembly kernel using quadrature representation.

\subsection{Code Generation for Quadrature Representation}
Rapid implementation of high performance, robust, and portable code evaluating element matrices using quadrature can be achieved through automated code generation. This has been succesfully proved in the context of the popular FEniCS project~\cite{Fenics}. The FEniCS Form Compiler (FFC) accepts as input the variational form of a partial differential equation and generates C++ code implementing local assembly routines. The variational form is expressed at high-level by means of the domain-specific Unified Form Language (UFL). Local assembly code must be high performance: as the complexity of a form increases, in terms of number of derivatives, pre-multiplying functions, and polynomial order of the chosen functions, the resulting kernels evaluating element matrices become more computationally expensive, which impacts significantly the run-time of the overall computation. 

Achieving high performance is non-trivial due to the complexity of the mathematical expressions involved in the numerical integration and because of the small sizes of loops and accessed arrays. In~\cite{quadrature1},~\cite{Kirby-FEM-opt} and~\cite{Francis}, it is shown how automated code generation allows the introduction of powerful optimizations, which a user cannot be expected to write ``by hand'', as well as the exploration of non-standard integration techniques, based, for instance, on symbolic manipulation. In~\cite{Luporini} we made one step forward by showing that different problems require distinct set of transformations if close-to-peak performance needs to be obtained, and that low-level, domain-aware code transformations, which are not supported by available compilers, are essential to maximize instruction-level parallelism and register locality. 

\subsection{Summary of Low-level Optimizations for Quadrature Representation}
\label{sec:summary-opts}
To neatly distinguish the contributions of this paper from those in~\cite{Luporini}, in this section we summarize the results of our previous work on automated code transformations for quadrature representation.

...TODO...

The work in~\cite{Luporini} resulted in the development of COFFEE\footnote{COFFEE stands for COmpiler For FinitE Element local assembly.}, a compiler for the optimization of local assembly kernels relying on quadrature representation.  

...TODO...

Temporary arrays can be placed at the right depth in the sorrounding loop nest to store values of sub-expressions that are invariant to one or more loops. 

...TODO...

% Far notare che low-level si, ma sono guidate da high-level knowledge! Questo in risposta alla domanda: ma allora perche' non sfruttare la domain knowledge che hai, che senso ha separare...

% Ci sono due goal: minimizzare flops e specializzare

% Vantaggio di automatizzare rispetto che scrivere a mano
% which would be practically unfeasible to achieve by hand-written code


\section{A Compiler for Optimizing Quadrature-based Integration}
In order to generate high performance code, mathematical expressions evaluating the element tensor must be optimized with regards to several interrelated aspects: 1) minimization of floating point operations, 2) instruction-level parallelism, and 3) data locality. In this paper, we tackle these three points building on our previous work (\cite{Luporini}). 

...We propose a novel structure of how we think a platform-independent, domain-specific optimizing compiler should look like....

...The Expression Re-writer is a software module implemented in COFFEE dealing with the first point...

...The Code Specializer (henceforth CS) is...
A key point is that the ER has to perform transformations that do not break the code specializer. Having indirections is really dangerous...

\section{Expression Re-writing}
\label{sec:expr-rewriting}
As summarized in~\ref{sec:summary-opts}, loop-invariant code motion is the key to reduce the computational intensity of a mathematical expression. The Expression Re-writer (henceforth ER) that we have designed and implemented in COFFEE enhances this technique making two steps forward. 

Firstly, exploiting arithmetic operations properties like associativity, distributivity, and commutativity, it manipulates the original expression to expose more opportunities to the code hoister. There are many ways an expression can be re-written into, and the search space can become considerably big. Therefore, one problem we solve is finding a sufficiently simple yet systematic way of maximizing the amount of loop-invariant operations in an expression. In Section~\ref{sec:rewriting-rules}, we formalize the set of re-writing rules that COFFEE follows to transform an expression. 

Secondly, the ER re-structures the loop nest so as to eliminate arithmetic operations over array columns that are statically known to be zero-valued. Zero columns in tabulated basis functions appear, for example, when taking derivatives on a reference element or when using mixed elements. A code transformation eliminating floating point operations on zeros was presented in~\cite{quadrature1}; however, by using indirection arrays in the generated code, it breaks many of the optimizations that can be applied at the Code Specializer level, including SIMD vectorization. In Section~\ref{sec:zeros}, we show a novel approach to avoiding computation on zeros based on symbolic execution.

%In COFFEE, the application of the re-writing rules preceds the elimination of operations on zeros. 

%It is worth noting how writing these transformations ``by hand'' would be practically unfeasible, especially when the expressions are particularly complex.
%
%
%In this section, we describe our efforts in producing a more effective tool capable of explore how to leverage automated code generation to expose more opportunities to the code hoister. 
%
%Automated code generation, however, Mathematical expressions can be transformed to decrease the number of arithmetic operations required to evaluate the element tensor. A first 
%
%Minimizing the number of floating point operations for evaluating the element tensor of a generic form
%

\subsection{Re-writing Rules}
\label{sec:rewriting-rules}
\begin{figure}
\scriptsize
\lstinputlisting{listings/simple.code}
\label{original-code}\caption{Original code}
\end{figure}

Consider the simplified yet representative example of the element matrix computation in Figure~\ref{original-code}. ...TODO: describe. We will use this example throughout the rest of the paper for illustrative purpose. 

A first glimpse of the code easily suggests that the sub-expression ... . A closer look also highlights that ... .
Also, ...can precompute once. And doing that in a loop, at the expense of extra memory, to trigger autovect. These observations lie at the heart of the generalized loop-invariant code motion technique presented in~\cite{Luporini}. 



\subsection{Avoiding Iteration on Zero-blocks with Symbolic Execution}
\label{sec:zeros}

\section{Code Specialization}
\label{sec:code-spec}

\subsection{Standard Compiler Transformations}

\subsection{Precomputation of Invariant Terms}

\subsection{Exposing Linear Alegbra Operations}

\subsection{Model-driven Autotuning}

%\begin{algorithm}[t]
%\SetAlgorithmName{LISTING}{}
%\footnotesize
%\KwSty{void} helmholtz(double A[3][4], double **coords) $\lbrace$\\
%~~\KwSty{$\#$define} ALIGN $\_\_$attribute$\_\_$((aligned(32))) \\
%~~// K, det = Compute Jacobian (coords) \\
%~~\\
%~~\KwSty{static const double} W[3] ALIGN = $\lbrace$...$\rbrace$\\
%~~\KwSty{static const double} X$\_$D10[3][4] ALIGN = $\lbrace\lbrace$...$\rbrace\rbrace$\\
%~~\KwSty{static const double} X$\_$D01[3][4] ALIGN = $\lbrace\lbrace$...$\rbrace\rbrace$\\
%~~\\
%~~\KwSty{for} (\KwSty{int} i = 0; i$<$3; i++) $\lbrace$ \\
%~~~~double LI$\_$0[4] ALIGN;\\
%~~~~double LI$\_$1[4] ALIGN;\\
%~~~~\KwSty{for} (\KwSty{int} r = 0; r$<$4; r++) $\lbrace$ \\
%~~~~~~LI$\_$0[r] = ((K1*X$\_$D10[i][r])+(K3*X$\_$D01[i][r]));\\
%~~~~~~LI$\_$1[r] = ((K0*X$\_$D10[i][r])+(K2*X$\_$D01[i][r]));\\
%~~~~$\rbrace$\\
%~~~~\KwSty{for} (\KwSty{int} j = 0; j$<$3; j++) \\
%~~~~~~\KwSty{$\#$pragma vector aligned}\\
%~~~~~~\KwSty{for} (\KwSty{int} k = 0; k$<$4; k++) \\
%~~~~~~~~A[j][k] += (Y[i][k]*Y[i][j]+LI$\_$0[k]*LI$\_$0[j]+LI$\_$1[k]*LI$\_$1[j])*det*W[i]);\\
%~~$\rbrace$\\
%$\rbrace$
%\caption{Local assembly code for the Helmholtz problem in
%  Listing~\ref{code:helmholtz} after application of padding, data
%  alignment, and \emph{licm}, for an AVX architecture. In this
%  example, sub-expressions invariant to \texttt{j} are identical to
%  those invariant to \texttt{k}, so they can be precomputed once in
%  the $r$ loop.}
%\label{code:helmholtz-licm}
%\end{algorithm}

%\begin{figure}[b]
%\begin{center}
%\includegraphics[scale=0.75]{Pictures/coffee-pipeline.pdf}
%\caption{High-level view of Firedrake. COFFEE is at the core,
%  receiving ASTs from a modified version of the FEniCS Form compiler
%  and producing optimized C code kernels.}
%\label{fig:coffee-pipeline}
%\end{center}
%\end{figure}

\section{Performance Evaluation}
\label{sec:perf-results}

\subsection{Experimental Setup}

%Experiments were run on a single core of two Intel architectures, a
%Sandy Bridge (I7-2600 CPU, running at 3.4GHz, 32KB L1 cache and 256KB
%L2 cache) and a Xeon Phi (5110P, running at 1.05Ghz in native mode,
%32KB L1 cache and 512KB L2 cache). We have chosen these two
%architectures because of the differences in the number of logical
%registers and SIMD lanes, which can impact the effectiveness of the
%optimization strategy. The \texttt{icc 13.1} compiler was used. On the
%Sandy Bridge, the compilation flags used were \texttt{-O2} and
%\texttt{-xAVX} for auto-vectorization. On the Xeon Phi, optimization
%level \texttt{-O3} was used. Other optimization levels performed, in
%general, slightly worse.

%\newcommand{\licmapresultsnorms}{
%\begin{tabulary}{1.0\textwidth}{cccccc|cccc}
%\cline{3-10}
%& & \multicolumn{4}{c}{\texttt{Sandy Bridge}} & \multicolumn{4}{c}{\texttt{Xeon Phi}} \\
%\cline{1-10}
%\texttt{problem} & \texttt{shape} & \texttt{p1} & \texttt{p2} & \texttt{p3} & \texttt{p4} & \texttt{p1} & \texttt{p2} & \texttt{p3} & \texttt{p4} \\[0.1cm]
%\texttt{Helmholtz} & \texttt{triangle} & 1.32 & 1.88 & 2.87 & 4.13 & 1,50 & 2,41 & 1,30 & 1,96 \\
%\texttt{Helmholtz} & \texttt{tetrahedron} & 1.35 & 3.32 & 2.66 & 3.27 & 1,41 & 1,50 & 2,79 & 2,81 \\
%\texttt{Helmholtz} & \texttt{prism} & 2.63 & 2.74 & 2.43 & 2.75 & 2,38 & 2,47 & 2,15 & 1,71\\[0.1cm]
%%\cline{1-18}
%\texttt{Diffusion} & \texttt{triangle} & 1.38 & 1.99 & 3.07 & 4.28 & 1,08 & 1,88 & 1,20 & 1,97\\
%\texttt{Diffusion} & \texttt{tetrahedron} & 1.41 & 3.70 & 3.18 & 3.82 & 1,05 & 1,51 & 2,76 & 3,00\\
%\texttt{Diffusion} & \texttt{prism} & 2.55 & 3.13 & 2.73 & 2.69 & 2,41 & 2,52 & 2,05 & 2,48\\[0.1cm]
%%\cline{1-18}
%\texttt{Burgers} & \texttt{triangle} & 1.56 & 2.28 & 2.61 & 2.77 & 2,84 & 2,26 & 3,96 & 4,27 \\
%\texttt{Burgers} & \texttt{tetrahedron} & 1.61 & 2.10 & 1.60 & 1.78 & 1,48 & 3,83 & 1,55 & 1,29 \\
%\texttt{Burgers} & \texttt{prism} & 2.19 & 2.32 & 1.64 & 1.42 & 2,18 & 2,82 & 1,24 & 1,25 \\
%\cline{1-10}
%\end{tabulary}
%}
%
%\begin{table*}[t]
%\tbl{Performance improvement due to generalized loop-invariant code
%  motion, data alignment, and padding, for different element shapes
%  (triangle, tetrahedron, prism) and polynomial orders ($p \in [1,
%    4]$), over the original non-optimized code, for the Helmholtz,
%  Diffusion and Burgers problems.}{ \scriptsize \licmapresultsnorms }
%\label{table:perf-results-licmap}
%\end{table*}

\subsection{Results for Forms of Increasing Complexity}


\section{Conclusions}
\label{sec:conclusions}


% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{biblio}


\medskip

\end{document}
